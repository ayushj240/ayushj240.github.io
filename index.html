<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 35px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Ayush Jain</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Ayush Jain</name>
              </p>
              <!-- <p>I am a Computer Science PhD student in <a href="https://clvrai.com">Cognitive Learning for Vision and Robotics Lab (CLVR)</a>, at University of Southern California, advised by Prof. <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a>. My research interests include Reinforcement Learning, Deep Learning, and Robotics. -->
              <p>I am a Computer Science PhD student in at University of Southern California, co-advised by Prof. <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a> and Prof. <a href="https://ebiyik.github.io/">Erdem B&#305;y&#305;k</a>.
              I was fortunate to intern at <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>, <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/">Microsoft Research Montreal</a> and <a href="https://clova.ai/en/research/research-areas.html">Naver AI, Seoul</a>. Before joining USC, I spent two years in Seoul, working at <a href="https://research.samsung.com/aicenter_seoul">Samsung Research Korea</a>. Earlier, I graduated from <a href="http://home.iitd.ac.in">IIT Delhi</a>, where I worked under the guidance of Prof. <a href="http://web.iitd.ac.in/~sumeet">Sumeet Agarwal</a> and Prof. Rajakrishnan Rajkumar.
              </p>
              <p>
              <strong>Research Goal</strong>: To build adaptive and capable agents for both physical and virtual worlds. I work on reinforcement learning algorithms and architectures that learn under <strong>complex action spaces</strong> that are large, unseen, varying, or difficult to optimize.
              </p>
              <p align=center>
                <a href="mailto:ayushj@usc.edu">Email</a> &nbsp|&nbsp
                <a href="https://twitter.com/Ayushj240">Twitter</a> &nbsp|&nbsp
                <a href="data/Ayush_Jain_CV.pdf">CV</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?user=-zEc_sAAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp|&nbsp
                <a href="https://www.linkedin.com/in/ayushj240"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/ayush2022_2.jpg" width="200">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <!--
              <p>
                I am primarily interested in giving artificial agents the ability to think, understand and act in novel circumstances. My research involves using reinforcement learning and representation learning to achieve generalizable and adaptable agents for reasoning, recommender systems, and robotics.
              </p>
              -->
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <td width="30%">
            <a href="https://qmp-mtrl.github.io/">
              <img src="images/qmp_teaser.png" href="https://openreview.net/pdf?id=U3n8WPtKPm" alt="QMP Teaser" width="300" height="160" type="image/png">
            </a>
          </td>
            <td valign="middle" width="70%">
              <a href="https://arxiv.org/abs/2302.00671">
                <papertitle>QMP: Q-switch Mixture of Policies for Multi-Task Behavior Sharing</papertitle>
              </a>
              <br>
              <a href="https://gracehzhang.github.io/">Grace Zhang</a>*,
              <strong>Ayush Jain</strong>*,
              Injune Hwang,
              <a href="https://shaohua0116.github.io/">Shao-Hua Sun</a>,
              <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a>
              <br>
              <em>International Conference on Learning Representations (ICLR), 2025</em>
              <br>
              <p>We introduce behavior-sharing for efficient multitask reinforcement learning, complementary with parameter-sharing and data-sharing.</p>
              <a href="https://openreview.net/forum?id=aUZEeb2yvK">Paper</a> |
              <a href="https://arxiv.org/abs/2302.00671">arXiv</a> |
              <a href="https://qmp-mtrl.github.io/">Project Page</a>
              <p></p>
            </td>

        </table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
           <td width="30%">
            <a href="https://arxiv.org/abs/2410.11833">
              <img src="images/teaser_savo.png" href="https://arxiv.org/abs/2410.11833" alt="SAVO Teaser" width="300" height="120" type="image/png"></td>
            </a>
            <td valign="middle" width="70%">
              <a href="https://arxiv.org/abs/2410.11833">
                <papertitle>Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions</papertitle>
              </a>
              <br>
              <strong>Ayush Jain</strong>,
              <a href="https://rowing0914.github.io/">Norio Kosaka</a>,
              Xinhu Li,
              <a href="https://bi.snu.ac.kr/~kmkim/">Kyung-Min Kim</a>,
              <a href="https://ebiyik.github.io/">Erdem B&#305;y&#305;k</a>,
              <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a>
              <br>
              <em>preprint</em>
              <br>
              <p>We identify that TD3 gets stuck in local optima in tasks with complex Q-functions and propose a new actor architecture to find better optima.</p>
              <a href="https://arxiv.org/abs/2410.11833">arXiv</a>
              <p></p>
            </td>

        </table>





        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <!-- <td width="30%"><img src="images/agile_result_teaser.png" alt="AGILE Teaser" width="300" height="260"></td> -->
          <td width="30%">
              <a href="https://openreview.net/forum?id=MljXVdp4A3N">
                 <video muted autoplay loop src="images/Agile_teaser_video_720p.mp4" alt="AGILE Teaser Video" width="300" height="225" type="video/mp4">
              </a>
          </td>
            <td valign="middle" width="70%">
              <a href="https://openreview.net/forum?id=MljXVdp4A3N">
                <papertitle>Know Your Action Set: Learning Action Relations for Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Ayush Jain*</strong>,
              <a href="https://rowing0914.github.io/">Norio Kosaka</a>*,
              <a href="https://bi.snu.ac.kr/~kmkim/">Kyung-Min Kim</a>,
              <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a>
              <br>
              <em>International Conference on Learning Representations (ICLR), 2022</em>
              <br>
              <p>For optimal decision-making under a varying action space, we learn the relations between the available actions using a graph-attention network based policy architecture.</p>
              <a href="https://openreview.net/pdf?id=MljXVdp4A3N">Paper</a> |
              <a href="https://sites.google.com/view/varyingaction">Project Page</a> |
              <a href="https://github.com/clvrai/agile">Code</a> |
              <a href="https://iclr.cc/virtual/2022/poster/6594">Talk</a>
              <p></p>
            </td>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="30%">
            <a href="http://proceedings.mlr.press/v119/jain20b.html">
               <video muted autoplay loop src="images/create_teaser_video_high_res.mp4" alt="CREATE Teaser Video" width="300" height="250" type="video/mp4">
             </a>
          </td>
            <td valign="middle" width="70%">
              <a href="http://proceedings.mlr.press/v119/jain20b/jain20b.pdf">
                <papertitle>Generalization to New Actions in Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Ayush Jain*</strong>,
              <a href="https://www.andrewszot.com/">Andrew Szot</a>*,
              <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a>
              <br>
              <em>International Conference on Machine Learning (ICML), 2020</em>
              <br>
              <p>Our proposed RL framework enables agents to solve sequential decision-making tasks even when the available actions (tools or skills) have not been seen before.</p>
              <a href="http://proceedings.mlr.press/v119/jain20b.html">Paper</a> |
              <a href="https://sites.google.com/view/action-generalization">Project Page</a> |
              <a href="https://arxiv.org/abs/2011.01928">arXiv</a> |
              <a href="https://github.com/clvrai/new-actions-rl">Code</a> |
              <a href="https://icml.cc/virtual/2020/poster/5768">Talk</a> |
              <a href="https://clvrai.com/create/">Environment</a>
              <p></p>
            </td>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
           <td width="30%"><img src="images/uid_image.png" alt="UID" width="300" height="180"></td>
            <td valign="middle" width="70%">
              <a href="http://aclweb.org/anthology/W18-4605">
                <papertitle>Uniform Information Density Effects on Syntactic Choice in Hindi</papertitle>
              </a>
              <br>
              <strong>Ayush Jain*</strong>,
              <a href="https://sites.google.com/view/vishal-singh">Vishal Singh</a>*,
              Sidharth Ranjan*,
              Rajakrishnan Rajkumar,
              <a href="http://web.iitd.ac.in/~sumeet">Sumeet Agarwal</a>
              <br>
              <em>Workshop on Linguistic Complexity and Natural Language Processing, COLING 2018</em>
              <br>
              <p></p>
              <p>This work investigates the extent to which word order choices in Hindi language are influenced by the drive to minimize the information variance in a sentence.</p>
            </td>

        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
            <td>
              <heading>Teaching</heading>
            </td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="5">
          <tr>
            <td width="70%" valign="middle">
              <p>
              Teaching Assistant (USC): <papertitle>Deep Learning and its Applications (CSCI566, CSCI599)</papertitle>
                <ul>
                    <li>Fall 2024: <em>Prof. Yan Liu</em></li>
                    <li>Spring 2024: <em>Prof. Yue Zhao</em></li>
                    <li>Spring 2023: <em>Prof. Jesse Thomason</em></li>
                    <li>Fall 2020: <em>Prof. Joseph J Lim</em></li>
                    <li>Spring 2019: <em>Prof. Joseph J Lim</em></li>
                    <li>Fall 2019: <em>Prof. Joseph J Lim</em></li>
                </ul>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
          <td>
            <heading>Reviewing</heading>
          </td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="5">
          <tr>
            <td width="70%" valign="middle">
                <ul>
                    <li><strong>ICLR:</strong> 2023, 2024, 2025</li>
                    <li><strong>NeurIPS:</strong> 2023, 2024</li>
                    <li><strong>CoRL:</strong> 2021, 2022, 2023, 2024</li>
                </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Credits to the
                  <a href="https://jonbarron.info/">
                    <font size="2">
                      Coolest template!
                    </font>
                  </a>
                </font>
              </p>
            </td>
          </tr>
        </table>



        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
